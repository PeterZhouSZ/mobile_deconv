\documentclass{beamer}

\usetheme{CambridgeUS}
\usecolortheme{beaver}

\usepackage{amsmath}
\usepackage{dsfont}

\usepackage{t1enc}
\usepackage{float}
\usepackage{graphicx}
\usepackage{verbatim}
\usepackage{subfigure}

\setbeamertemplate{itemize items}[default]
\setbeamertemplate{enumerate items}[default]

%\usepackage{beamerthemesplit}

%\setbeamerfont{structure}{family=\rmfamily,shape=\itshape} 

% IEEE transaction type bibliography
% Citations are numbered based on the order of appearance
\bibliographystyle{ieeetr}
% In the bibliography slide, numbers will not 
% appear by default in beamer. This will make 
% numbered bibliography.
%\setbeamertemplate{bibliography item}[text]

% Use abc in footnote
\renewcommand{\thefootnote}{\fnsymbol{footnote}}


\title[Utilizing Motion Sensor Data for Some Image Processing Applications]
%\hspace{55pt}
%\insertframenumber/\inserttotalframenumber]
{Utilizing Motion Sensor Data for Some Image Processing Applications}
\author[Saragadam R V Vishwanath]%IIT Madras \hspace{25pt} EE11S063]
{Saragadam R V Vishwanath (EE10B035)\\
\vspace{3pt}
\small{Under the guidance of Prof.\ A. N. Rajagopalan}
}
%\vspace{15pt}
\institute[IIT Madras]{
Department of Electrical Engineering\\
IIT Madras}
\date{May 15, 2014}


% Set pdf props
\usepackage{hyperref}
\hypersetup
{
    pdfauthor={Saragadam R V Vishwanath (EE10B035)},
    pdfsubject={B.Tech project viva},
    pdftitle={Utilizing Motion Sensor Data for Some Image Processing Applications},
    pdfkeywords={btech,thesis,report,image processing,motion sensors, inertial sensors}
}

\setbeamertemplate{title page}[default][colsep=-4bp,rounded=true]

\begin{document}

\begin{frame}
\titlepage
\end{frame}

% An outline of how we want to present our results. Remember that we have only
% 15 slides in total. Hence, Introduction, 3 per project and conclusion will 
% complete it. The 3 per project slides can be split as follows:
% -- Introduction and what is the algorithm.
% -- Experimental results.
% -- Conclusion and reflection.

% Motivation ------------------------------------------------------------------- 
\begin{frame}{Motivation}
\begin{itemize}
	\item Hand held devices get shaken when held loosely. Image degradation
	by motion blur. Can be used for various purposes.
	\item Computational photography now moving to ubiquitous mobiles
	\item Increased computational power. Hence, increased avenues.
	\item Additional data in the form of motion sensors. Increased scope
	of research.
	\item Flexible programming on the mobile camera. Ability to implement
	algorithms on the fly instead of offline computing.
	\item Not much work done in this area.
\end{itemize}
\end{frame}

% What do we have --------------------------------------------------------------
\begin{frame}{What do we have in hand}
\begin{itemize}
	\item A mobile that is easy to program.
	\begin{itemize}
		\item Access to three-axis accelerometer.
		\item Access to 5 mp camera with variable focus, exposure time and resolution.
		\item Access to TCP communication for sending data to computer.
	\end{itemize}
	\vspace{0.4cm}
	\item A desktop computer that is very fast.
	\begin{itemize}
		\item Python for writing all the applications.
		\item WiFi dongle to receive data wireless.
	\end{itemize}
\end{itemize}
\begin{center}
	\resizebox{30mm}{!} {\includegraphics {setup.png}}
\end{center}
\end{frame}

% Work done --------------------------------------------------------------------
\begin{frame}{Work Done}
\begin{itemize}
	\item Developing an application on mobile to send motion sensors 
	data and images over TCP. 
	\item Constructing a kernel with motion sensors data.
	\begin{itemize}
		\item Synchronizing the accelerometer with exposure time.
		\item Separating gravity and acceleration due to external force using
		low pass filtering.
	\end{itemize}
	\item Image deblurring using semi-blind methods.
	\item Estimating depth using motion blur and shape from focus.
	\item Image registration for pure translation and pure rotation cases.
\end{itemize}
\end{frame}

% Image deblurring -------------------------------------------------------------
\begin{frame}{Image Deblurring}{Primer}
\begin{itemize}
	\item Blur induced due to shake of the hand held camera. 
	\item Ill-posed if no more information is available.
	\item Idea is to get either the PSF directly or get a good initial
	estimate.
	\item Trajectory can be estimated using data from accelerometer. 
	\begin{itemize}
	\item No scene depth information. Hence we iterate through a possible set of 
	depths. 
	\item Drift due to erroneous gravity estimation. Hence we compensate by
	iterating through a set of possible drifts.
	\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{Image Deblurring}{Results}

Results of non-blind deconvolution using wiener deconvolution

\begin{figure}[H]
\begin{center}
	\resizebox{30mm}{!} {\includegraphics {../images/deblur/imblur.png}}
	\resizebox{30mm}{!} {\includegraphics {../images/deblur/imdeblur.png}}
	\resizebox{30mm}{!} {\includegraphics {../images/deblur/jia_blind_deconv.png}}
\end{center}
\end{figure}

Results of semi-blind deconvolution using Punnappurath et al's code.

\begin{figure}[H]
\begin{center}
\resizebox{30mm}{!} {\includegraphics {../images/semiblind/blurred.png}}
\resizebox{30mm}{!} {\includegraphics {../images/semiblind/blind.png}}
\resizebox{30mm}{!} {\includegraphics {../images/semiblind/semi_blind.png}}
\end{center}
\end{figure}

\end{frame}

\begin{frame}{Image Deblurring}{Inference}
\textbf{Pros}
\begin{itemize}
	\item Simple computation as we have enough data.
	\item Semi-blind performs same for high textured images. Converges
	quickly. Performs well for low textured images.
\end{itemize}
\textbf{Cons}
\begin{itemize}
	\item If only accelerometer data is available, PSF can go completely wrong.
	\item No information from the image used.
\end{itemize}
\textbf{Improvements}
\begin{itemize}
	\item Estimate a blind PSF and fuse it with calculated trajectory.
	\item Better estimation of kernel using other motion sensors data.
\end{itemize}
\end{frame}

% Depth estimation -------------------------------------------------------------
\begin{frame}{Depth Estimation}{Primer}
\begin{itemize}
	\item Depth estimation using motion blur
	\begin{itemize}
		\item Each pixel gets blurred by a different scale of the blur kernel,
		assuming no parallax
		\item We have a sharp image, blurred image and the PSF estimate. Need to
		estimate scale at each point.
	\end{itemize}
	\vspace{0.4cm}
	\item Depth estimation using shape from focus
	\begin{itemize}
		\item Farther the point from focus, more blurred the object becomes.
		\item Need a \emph{focus measure} which would peak when a region is 
		completely focused. We use Sum Modified Laplacian.
	\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{Depth Estimation}{Results -- Motion blur}

\textbf{Depth from motion blur -- Good case}

\begin{figure}[H]
\begin{center}
\resizebox{30mm}{!} {\includegraphics {../images/depth/eg1/preview_im_gray.png}}
\resizebox{30mm}{!} {\includegraphics {../images/depth/eg1/saved_im_gray.png}}
\resizebox{30mm}{!} {\includegraphics {../images/depth/eg1/imdepth.png}}
\caption{\scriptsize{Sharp image, blurred image and estimated depth. Brighter parts are closer to the camera.}}
\end{center}
\end{figure}
\vspace{-0.1cm}
\textbf{Depth from motion blur -- Bad case}

\begin{figure}[H]
\begin{center}
\resizebox{30mm}{!} {\includegraphics {../images/depth/eg3/preview_im.png}}
\resizebox{30mm}{!} {\includegraphics {../images/depth/eg3/saved_im_gray.png}}
\resizebox{30mm}{!} {\includegraphics {../images/depth/eg3/imdepth.png}}
\end{center}
\end{figure}

\end{frame}

\begin{frame}{Depth Estimation}{Results -- Shape from focus}

\textbf{Depth using shape from focus}
\begin{figure}[H]
\begin{center}
\resizebox{35mm}{!} {\includegraphics {../images/focus/eg1/im3.png}}
\resizebox{35mm}{!} {\includegraphics {../images/focus/eg1/imdepth.png}}
\resizebox{35mm}{!} {\includegraphics {../images/focus/eg1/imfocus.png}}
\caption{\scriptsize{First image in the set. Estimated depth map and fully
focused image. Darker regions are closer to the camera.}}
\end{center}
\end{figure}

\end{frame}

\begin{frame}{Depth Estimation}{Inference}
\textbf{Depth from motion blur}
\begin{itemize}
	\item Pros
		\begin{itemize}
			\item Low computational complexity.
			\item Not much data needed. Only two images and motion sensor
			data. Easily available on the mobile platform.
			\item Depth map is reliable with good kernel estimate.
		\end{itemize}
	\item Cons
		\begin{itemize}
			\item Shift in image pair or wrong kernel estimate gives a 
			very bad depth map.
		\end{itemize}
	\item Improvements
		\begin{itemize}
			\item Segmenting image for more reliability.
			\item A better metric than $L_2$ norm for comparing 
			blurred and the reblurred image.
		\end{itemize}
\end{itemize}
\vspace{0.2cm}
\textbf{Depth using shape from focus}
\begin{itemize}
	\item Need better focus operator for low frequency areas.
\end{itemize}
\end{frame}

% Image registration -----------------------------------------------------------
\begin{frame}{Image Registration}{Primer}
\begin{itemize}
	\item When capturing two images, we need the trajectory between the
	two positions.
	\item Simple registration may not work when one of the images is blurred.
	\item Motion sensors give the exact trajectory and can be used for registration.
	\item Even thoug hwe know the displacement in mm, we don't know in pixels, hence
	we iterate through a certain depths.
	\item With only accelerometer, we can either know the translation or rotation. Hence we see both the cases separately.
\end{itemize}
\end{frame}

\begin{frame}{Image Registration}{Results}
\textbf{Translation case}
\begin{figure}[H]
\begin{center}
	\resizebox{70mm}{!} {\includegraphics {../images/imreg/shift/eg1/imreg.png}}
\end{center}
\end{figure}
\textbf{Rotation case}
\begin{figure}[H]
\begin{center}
	\resizebox{70mm}{!} {\includegraphics {../images/imreg/rotation/eg2/imreg.png}}
\end{center}
\end{figure}
\end{frame}

\begin{frame}{Image Registration}{Inference}
\textbf{Translation}
\begin{itemize}
	\item Pros
		\begin{itemize}
			\item Low computational complexity.
			\item Search space drastically reduced to a small sector
		\end{itemize}
	\item Cons
		\begin{itemize}
			\item Bad calculated trajectory still a problem.
		\end{itemize}
\end{itemize}
\vspace{0.2cm}
\textbf{Rotation}
\begin{itemize}
	\item Pros
		\begin{itemize}
			\item Low computational complexity.
			\item Very robust for blurred images also
		\end{itemize}
	\item Cons
		\begin{itemize}
			\item Need to search for multiple positions in the exposure time,
			as the exposure time and accelerometer data are not synchronized.
			\item Does not compensate for translation.
		\end{itemize}
	\item Improvements
		\begin{itemize}
			\item Adding gyroscope can aid in translational registration also.
		\end{itemize}
\end{itemize}
\end{frame}

% Future developments ----------------------------------------------------------
\begin{frame}{Future Developments}
\begin{itemize}
	\item Mobile application is very versatile. Can be used for developing
	computational photography algorithms like video stabilization and super 
	resolution
	\item All the algorithms we implemented are computationally cheap. Can be
	ported to the mobile platform with ease.
	\item Lot more can be done in deblurring by developing semi-blind algorithms
	or multi-channel algorithms. 
\end{itemize}
\end{frame}

% Conclusion -------------------------------------------------------------------
\begin{frame}{Conclusion}
\begin{itemize}
	\item Mobile is a very versatile platform.
	\item Motion sensors very useful for various image processing applications.
	More accuracy and lesser computational load.
	\item Project has a lot of future scope for development.
\end{itemize}
\end{frame}
% End
\end{document}
